{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e27c846",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Artophilic\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "['ham' 'ham' 'spam' ... 'ham' 'ham' 'ham']\n",
      "['ham' 'ham' 'ham' ... 'ham' 'ham' 'ham']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      0.98      0.99      1448\n",
      "        spam       0.89      0.92      0.91       224\n",
      "\n",
      "    accuracy                           0.97      1672\n",
      "   macro avg       0.94      0.95      0.95      1672\n",
      "weighted avg       0.98      0.97      0.98      1672\n",
      "\n",
      "accuracy_score:  0.9748803827751196\n"
     ]
    }
   ],
   "source": [
    "#9A\n",
    "''' \n",
    "Aim: Implement Naive Bayes classifier.'''\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "# Load the data\n",
    "sms_data = pd.read_csv(\"C:/Users/Artophilic/Datascience Bootcamp/Practical/NLP_pract/spam.csv\", encoding='latin-1')\n",
    "# Rename columns if necessary\n",
    "sms_data.rename(columns={'v1': 'Category', 'v2': 'Message'}, inplace=True)\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "stemming = PorterStemmer()\n",
    "corpus = []\n",
    "for i in range(len(sms_data)):\n",
    "    s1 = re.sub('[^a-zA-Z]', ' ', sms_data['Message'][i])\n",
    "    s1 = s1.lower()\n",
    "    s1 = s1.split()\n",
    "    s1 = [stemming.stem(word) for word in s1 if word not in set(stopwords.words('english'))]\n",
    "    s1 = ' '.join(s1)\n",
    "    corpus.append(s1)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "countvectorizer = CountVectorizer()\n",
    "x = countvectorizer.fit_transform(corpus).toarray()\n",
    "print(x)\n",
    "y = sms_data['Category'].values\n",
    "print(y)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, stratify=y, random_state=2)\n",
    "# Multinomial Na√Øve Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "multinomialnb = MultinomialNB()\n",
    "multinomialnb.fit(x_train, y_train)\n",
    "# Predicting on test data\n",
    "y_pred = multinomialnb.predict(x_test)\n",
    "print(y_pred)\n",
    "# Results of our Models\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"accuracy_score: \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6e759d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I like to play cricket. I hated it in my childhood though\n",
      "VERB\n",
      "VBD\n",
      "verb, past tense\n",
      "I           PRON      PRP     pronoun, personal\n",
      "like        VERB      VBP     verb, non-3rd person singular present\n",
      "to          PART      TO      infinitival \"to\"\n",
      "play        VERB      VB      verb, base form\n",
      "cricket     NOUN      NN      noun, singular or mass\n",
      ".           PUNCT     .       punctuation mark, sentence closer\n",
      "I           PRON      PRP     pronoun, personal\n",
      "hated       VERB      VBD     verb, past tense\n",
      "it          PRON      PRP     pronoun, personal\n",
      "in          ADP       IN      conjunction, subordinating or preposition\n",
      "my          PRON      PRP$    pronoun, possessive\n",
      "childhood   NOUN      NN      noun, singular or mass\n",
      "though      SCONJ     IN      conjunction, subordinating or preposition\n",
      "google       VERB       VB       verb, base form\n",
      "google       PROPN      NNP      noun, proper singular\n",
      "85. ADP     : 1\n",
      "92. NOUN    : 2\n",
      "94. PART    : 1\n",
      "95. PRON    : 4\n",
      "97. PUNCT   : 1\n",
      "98. SCONJ   : 1\n",
      "100. VERB    : 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"c5ca9533d00248419f7985c08da6bf41-0\" class=\"displacy\" width=\"1490\" height=\"317.0\" direction=\"ltr\" style=\"max-width: none; height: 317.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">I</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"170\">like</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"170\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"290\">to</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"290\">PART</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"410\">play</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"410\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"530\">football.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"530\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"650\">I</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"650\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"770\">hated</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"770\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"890\">it</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"890\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1010\">in</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1010\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1130\">my</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1130\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1250\">childhood</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1250\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1370\">though</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1370\">SCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c5ca9533d00248419f7985c08da6bf41-0-0\" stroke-width=\"2px\" d=\"M70,182.0 C70,122.0 160.0,122.0 160.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c5ca9533d00248419f7985c08da6bf41-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,184.0 L62,172.0 78,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c5ca9533d00248419f7985c08da6bf41-0-1\" stroke-width=\"2px\" d=\"M310,182.0 C310,122.0 400.0,122.0 400.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c5ca9533d00248419f7985c08da6bf41-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M310,184.0 L302,172.0 318,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c5ca9533d00248419f7985c08da6bf41-0-2\" stroke-width=\"2px\" d=\"M190,182.0 C190,62.0 405.0,62.0 405.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c5ca9533d00248419f7985c08da6bf41-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">xcomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M405.0,184.0 L413.0,172.0 397.0,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c5ca9533d00248419f7985c08da6bf41-0-3\" stroke-width=\"2px\" d=\"M430,182.0 C430,122.0 520.0,122.0 520.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c5ca9533d00248419f7985c08da6bf41-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M520.0,184.0 L528.0,172.0 512.0,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c5ca9533d00248419f7985c08da6bf41-0-4\" stroke-width=\"2px\" d=\"M670,182.0 C670,122.0 760.0,122.0 760.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c5ca9533d00248419f7985c08da6bf41-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M670,184.0 L662,172.0 678,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c5ca9533d00248419f7985c08da6bf41-0-5\" stroke-width=\"2px\" d=\"M790,182.0 C790,122.0 880.0,122.0 880.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c5ca9533d00248419f7985c08da6bf41-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M880.0,184.0 L888.0,172.0 872.0,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c5ca9533d00248419f7985c08da6bf41-0-6\" stroke-width=\"2px\" d=\"M790,182.0 C790,62.0 1005.0,62.0 1005.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c5ca9533d00248419f7985c08da6bf41-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1005.0,184.0 L1013.0,172.0 997.0,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c5ca9533d00248419f7985c08da6bf41-0-7\" stroke-width=\"2px\" d=\"M1150,182.0 C1150,122.0 1240.0,122.0 1240.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c5ca9533d00248419f7985c08da6bf41-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">poss</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1150,184.0 L1142,172.0 1158,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c5ca9533d00248419f7985c08da6bf41-0-8\" stroke-width=\"2px\" d=\"M1030,182.0 C1030,62.0 1245.0,62.0 1245.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c5ca9533d00248419f7985c08da6bf41-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1245.0,184.0 L1253.0,172.0 1237.0,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c5ca9533d00248419f7985c08da6bf41-0-9\" stroke-width=\"2px\" d=\"M790,182.0 C790,2.0 1370.0,2.0 1370.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c5ca9533d00248419f7985c08da6bf41-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1370.0,184.0 L1378.0,172.0 1362.0,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#9B\n",
    "''' \n",
    "Aim: Speech tagging\n",
    "It assigns grammatical labels to words in a sentences.\n",
    "pos_tag() function assigns POS tags'''\n",
    "\n",
    "\n",
    "#1. Speech Tagging using spaCy\n",
    "import spacy \n",
    "import spacy.attrs #Contains integer values for linguistic features like POS,TAG\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\") #A small english model trained on common texts\n",
    "sp = spacy.load('en_core_web_sm') \n",
    "\n",
    "#Processes the string into a spacy Doc Object\n",
    "sen = sp(u\"I like to play cricket. I hated it in my childhood though\") \n",
    "print(sen.text) #Prints the original sentences\n",
    "\n",
    "\n",
    "print(sen[7].pos_) #Refers to the 8th token (word) in the sentence.\n",
    "print(sen[7].tag_) #Coarse-grained POS tag (like VERB).\n",
    "print(spacy.explain(sen[7].tag_)) #Fine-grained POS tag (like VBD = verb, past tense).\n",
    "#It gives human-readable explanation of the tag.\n",
    "\n",
    "#Looping through all words for POS\n",
    "''' \n",
    "It prints each word, its POS,TAG and explain, nicely aligned using f string.\n",
    "'''\n",
    "for word in sen:\n",
    "    print(f'{word.text:{12}}{word.pos_:{10}}{word.tag_:{8}}{spacy.explain(word.tag_)}')\n",
    "\n",
    "#Google as verb\n",
    "sen = sp(u'Can you google it?')\n",
    "word = sen[2]\n",
    "print(f'{word.text:{12}} {word.pos_:{10}} {word.tag_:{8}} {spacy.explain(word.tag_)}')\n",
    "\n",
    "#Google as noun\n",
    "sen = sp(u'Can you search it on google?')\n",
    "word = sen[5]\n",
    "print(f'{word.text:{12}} {word.pos_:{10}} {word.tag_:{8}} {spacy.explain(word.tag_)}')\n",
    "\n",
    "#Finding the number of POS tags\n",
    "sen = sp(u\"I like to play football. I hated it in my childhood though\")\n",
    "num_pos = sen.count_by(spacy.attrs.POS) #Counting frequency of each POS in the sentence.\n",
    "\n",
    "''' \n",
    "sen.vocab[k].text: Converts the integer POS ID to text (like VERB, NOUN).\n",
    "v: Frequency of that POS in the sentence.'''\n",
    "for k,v in sorted(num_pos.items()):\n",
    "    print(f'{k}. {sen.vocab[k].text:{8}}: {v}')\n",
    "\n",
    "#Visualizing parts of speech tags\n",
    "from spacy import displacy\n",
    "\n",
    "''' \n",
    "u before string: It refers to Unicode string.'''\n",
    "sen = sp(u\"I like to play football. I hated it in my childhood though\")\n",
    "\n",
    "#Use 'displacy.render' instead of 'displacy.serve'\n",
    "''' \n",
    "displacy.render(...): Visually shows how words relate grammatically (dependencies).\n",
    "style='dep': Shows dependency parse.\n",
    "options={'distance': 120}: Adjusts spacing between words for better visibility'''\n",
    "displacy.render(sen, style='dep', jupyter=True, options={'distance': 120})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e5319d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package state_union to\n",
      "[nltk_data]     C:\\Users\\Artophilic\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package state_union is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Artophilic\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\Artophilic\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('PRESIDENT', 'NNP'), ('GEORGE', 'NNP'), ('W.', 'NNP'), ('BUSH', 'NNP'), (\"'S\", 'POS'), ('ADDRESS', 'NNP'), ('BEFORE', 'IN'), ('A', 'NNP'), ('JOINT', 'NNP'), ('SESSION', 'NNP'), ('OF', 'IN'), ('THE', 'NNP'), ('CONGRESS', 'NNP'), ('ON', 'NNP'), ('THE', 'NNP'), ('STATE', 'NNP'), ('OF', 'IN'), ('THE', 'NNP'), ('UNION', 'NNP'), ('January', 'NNP'), ('31', 'CD'), (',', ','), ('2006', 'CD'), ('THE', 'NNP'), ('PRESIDENT', 'NNP'), (':', ':'), ('Thank', 'NNP'), ('you', 'PRP'), ('all', 'DT'), ('.', '.')]\n",
      "[('Mr.', 'NNP'), ('Speaker', 'NNP'), (',', ','), ('Vice', 'NNP'), ('President', 'NNP'), ('Cheney', 'NNP'), (',', ','), ('members', 'NNS'), ('of', 'IN'), ('Congress', 'NNP'), (',', ','), ('members', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('Supreme', 'NNP'), ('Court', 'NNP'), ('and', 'CC'), ('diplomatic', 'JJ'), ('corps', 'NN'), (',', ','), ('distinguished', 'JJ'), ('guests', 'NNS'), (',', ','), ('and', 'CC'), ('fellow', 'JJ'), ('citizens', 'NNS'), (':', ':'), ('Today', 'VB'), ('our', 'PRP$'), ('nation', 'NN'), ('lost', 'VBD'), ('a', 'DT'), ('beloved', 'VBN'), (',', ','), ('graceful', 'JJ'), (',', ','), ('courageous', 'JJ'), ('woman', 'NN'), ('who', 'WP'), ('called', 'VBD'), ('America', 'NNP'), ('to', 'TO'), ('its', 'PRP$'), ('founding', 'NN'), ('ideals', 'NNS'), ('and', 'CC'), ('carried', 'VBD'), ('on', 'IN'), ('a', 'DT'), ('noble', 'JJ'), ('dream', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "#2. Speech tagging using nktl\n",
    "import nltk\n",
    "from nltk.corpus import state_union\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "''' \n",
    "state_union: Preloaded speeches.\n",
    "PunktSentenceTokenizer: A pre-trained unsupervised sentence tokenizer.'''\n",
    "\n",
    "# Download the 'state_union' corpus\n",
    "nltk.download('state_union')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "\n",
    "# Create our training and testing data:\n",
    "train_text = state_union.raw(\"2005-GWBush.txt\")\n",
    "sample_text = state_union.raw(\"2006-GWBush.txt\")\n",
    "\n",
    "# Train the Punkt tokenizer:\n",
    "custom_sent_tokenizer = PunktSentenceTokenizer(train_text)\n",
    "# Tokenize:\n",
    "tokenized = custom_sent_tokenizer.tokenize(sample_text)\n",
    "def process_content():\n",
    "    try:\n",
    "        for i in tokenized[:2]: # Properly indented loop\n",
    "            words = nltk.word_tokenize(i)\n",
    "            tagged = nltk.pos_tag(words)\n",
    "            print(tagged)\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "# Call the function once (removed recursive call inside itself)\n",
    "process_content()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde1a3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "practvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
